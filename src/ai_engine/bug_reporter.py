import json
import sys
from pathlib import Path
from datetime import datetime

sys.path.insert(0, str(Path(__file__).parent.parent))
from utils.openai_client import OpenAIClient
from utils.config import config
from utils.logger import get_logger

logger = get_logger(__name__)


def generate_bugs_report(healing_analysis_path: str = None) -> str:
    project_root = config.get_project_root()
    
    if healing_analysis_path is None:
        healing_analysis_path = "reports/healing_analysis.json"
    
    analysis_path = project_root / healing_analysis_path
    
    if not analysis_path.exists():
        logger.warning(f"Healing analysis file not found: {analysis_path}")
        return ""
    
    with open(analysis_path, "r") as f:
        analysis = json.load(f)
    
    actual_defects = analysis.get("actual_defects", [])
    
    if not actual_defects:
        logger.info("No actual defects found - skipping BUGS.md generation")
        return ""
    
    logger.info(f"Generating detailed bug report for {len(actual_defects)} defect(s)...")
    
    client = OpenAIClient()
    
    timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    bugs_md = f"""# Bug Report

**Generated**: {timestamp}  
**Total Defects Found**: {len(actual_defects)}

---

## Summary

The AI test automation framework identified **{len(actual_defects)} potential bug(s)** in the application during test execution. These failures were classified as ACTUAL_DEFECT (not test errors) and require manual investigation.

---

## Defects Requiring Investigation

"""
    
    for idx, defect in enumerate(actual_defects, 1):
        test_name = defect.get("test_name", "Unknown")
        confidence = defect.get("confidence", "unknown")
        error = defect.get("error", "N/A")
        analysis = defect.get("analysis", "N/A")
        healing_attempts = defect.get("healing_attempts", 0)
        
        logger.info(f"Analyzing defect {idx}/{len(actual_defects)}: {test_name}")
        
        bugs_md += f"""### Bug #{idx}: {test_name}

**Confidence Level**: {confidence.upper()}  
**Classification**: ACTUAL_DEFECT  
"""
        
        if healing_attempts > 0:
            bugs_md += f"**Healing Attempts Before Classification**: {healing_attempts}  \n"
        
        bugs_md += f"""
**Error Message**:
```
{error}
```

**Initial AI Analysis**:
{analysis}

---

"""
        
        try:
            detailed_analysis = client.analyze_bug(defect)
            bugs_md += f"{detailed_analysis}\n\n---\n\n"
        except Exception as e:
            logger.error(f"Could not generate detailed analysis: {e}")
            bugs_md += f"*Detailed analysis unavailable*\n\n---\n\n"
    
    bugs_md += f"""## Next Steps

1. **Review Each Bug**: Examine the detailed analysis above
2. **Prioritize**: Focus on high-confidence, critical severity bugs first
3. **Investigate**: Follow the suggested investigation areas
4. **Reproduce**: Use the reproduction steps to confirm the bug
5. **Fix**: Implement fixes based on potential solutions
6. **Verify**: Re-run tests after fixes to confirm resolution

## Notes

- These bugs were identified by AI analysis of test failures
- Confidence levels indicate AI's certainty about the classification
- Some bugs may be false positives - verify before fixing
- Tests that caught these bugs are NOT healed automatically
- Original test code preserved for bug reproduction

---

*Report generated by AI Test Automation Framework*
"""
    
    bugs_path = project_root / "reports" / "BUGS.md"
    bugs_path.parent.mkdir(parents=True, exist_ok=True)
    
    with open(bugs_path, "w") as f:
        f.write(bugs_md)
    
    logger.info(f"Bug report saved to: {bugs_path}")
    
    return str(bugs_path)


if __name__ == "__main__":
    bugs_file = generate_bugs_report()
    if bugs_file:
        logger.info(f"Bug report generated: {bugs_file}")
    else:
        logger.info("No bugs to report")
